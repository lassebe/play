\documentclass{article}

\begin{document}
\section{The problem}
All the papers deal with the Backward Induction Paradox that arises in classical Game Theory. It shows up in a number of games, such as the Centipede Game introduced by Rosenthal (1982), the finitely repeated Prisoners Dilemma, and the Chain-Store game.
\\
\\
While the structure of the games causes the reasoning to be slightly different in each example, the main idea behind the paradox is an alternating step-wise reasoning from the penultimate state to the initial state, which is where the Backwards part of Backwards Induction comes from. It works under the assumption that both players are rational, and their rationality is common knowledge %OR BELIEF DEPENDING ON WHO YOU ASK?
(that is each player knows that the other knows that she knows that ad infinitum). The paradoxical result of that reasoning is that the actions classical Game Theory advocate are both unintuitive and seem far removed from observed behaviour.
\\
\\
I'll try to briefly summarise three papers that try to tackle this topic, spend some time comparing them, and then give my own account of how I view the paradox and I how I believe it should be resolved. 

\section{The papers}
\subsection{Pettit \& Sugden}
Pettit and Sugden set out to prove that the arguments that underly the Backward Induction-solution are unsound. They formulate the paradox as a repeated Prisoner's Dilemma, where the paradox is dependent on the rationality of the players, and common belief of rationality. That is, both players believe that the other is rational, and that the other believes that she believes etc. Given such a belief structure, the players are convinced that the other will always defect, because that will maximise expected pay-off.
\\
\\
The main point of contention, as far as I'm able to tell, is that the Backward Induction argument ignores "past information". They argue that in if in the Prisoner's Dilemma, a player should ever cooperate, than she cleary invalidates the common belief of rationality because she diverged from the Backward Induction strategy of always defecting. Either the player who cooperated is irrational, or she believes that she can coerce the other to behave irrationally, that is, she doesn't believe that her opponent is rational. With this potential breaking in mind, they argue that neither player can be sure that the common belief in rationality will endure and without that surety the players are not able to complete the reasoning that leads to the Backward Induction solution. They also note, that in their opinion, even if both players believe that the common belief in rationality will survive no matter what happens in the game, it might not be sufficient for the Backward Induction solution to obtain.
\\
\\
Having, in their own words, solved the paradox, Pettit and Sugden turn to what they call the intuitive conclusion; wherein the players try to establish at least a temporary cooperation. They mention Tit-for-tat as an example of a strategy that might be more successful, but still cannot be regarded as rational. From there they expand Tit-for-tat into a strategy which is basically based on tricking the other into beliving that you are playing the irrational Tit-for-tat strategy, for as long as possible. They then present a number of examples of belief structures that a player can hold, which would make a delayed Tit-for-tat strategy a rational choice. The main idea here is to get the other to cooperate for a little bit longer than you do, so you both reap the rewards of cooperation, and you get a small extra pay-off for defecting earlier. However, as they are careful to explain, this does not mean that it is uniquely rational to cooperate initially. Instead, it depends on what beliefs are held by the player. 
\\
\\
They then bring up some counter-arguments, including the idea that all belief might be common. They explain that this might cause the players to be able to infer each others reasoning. But they argue that their argument still applies, even under these stronger conditions. They proceed to similarly defend their reasoning for delayed Tit-for-strategy. 
\\
\\
After that they turn to the situation where rationality is not only common belief but common knowledge. Here they admit that their argument falls apart. Common knowledge can't break down in the same way that belief can. But Pettit and Sugden feel that the paradox is inapplicable, because in a situation where common knowledge of rationality holds it's uninteresting to ask oneself about a situation where one player cooperates, because such a situation can never arise. Because of this Pettit and Sugden dismiss common knowledge of rationality as something that "ought to have no interest for game theory", since it in their view leaves no room for any form of strategic thinking.








\subsection{Bicchieri}

Bicchieri instead shapes her paper around what see calls common knowledge of rationality by framing it around the question of how much knowledge about the others beliefs the players need for the Backward Induction solution to obtain. According to Bicchieri more information doesn't necessarily help the players to make better predicitions. At the point where the knowledge of the theory of the game becomes common knowledge, the theory of the game becomes inconsistent.
\\
\\
She defines consistency with regards to a theory of a game, as being free from contradiction given any information set, or state of the game (including previous actions). It's enough for one player to have an inconsistent theory, for the others to also become inconsistent, because their theories in turn are dependent on the theory of that player.
\\
\\
From there she claims that if common knowledge does indeed make players theories inconsistent, it means that common knowledge can explain how players can play strategies that diverge from the one suggested by Backward Induction, and still remain individually rational.
\\
\\
Biccieri then demonstrates how the Backward Induction solution can obtain both when the players have the same set of beliefs and when their beliefs differ. Under the assumption that the players don't know what the other belives.
\\
\\
But what about the case when both players know what the other believes? When the beliefs are common knowledge. In this case Bicchieri brings up a game similar to the Centipede Game, and argues that if Player 1 chooses to continue the game (going against the Backward Induction Solution) the second player cannot think that this is because Player 1 believes her to be irrational, nor that Player 1 believes that she thinks he is irrational, this leaves the only option that Player 1 is irrational. But because beliefs are common knowledge, she knows that Player 1 believes himself to be rational, and this belief (given some additional assumptions) implies that he knows that he is rational, and one can only know true things. Bicchieri means that therefore there is no way for Player 2 to maintain her beliefs, either Player 1 is irrational, or he is trying to trick her (doesn't believe she is rational), and her theory is rendered inconsistent. 
\\
\\
She then goes on to talk about the communication of beliefs, and thereby making them common knowledge. This doesn't really play into the larger idea of the paradox, so I will refrain from describing it in greater detail.
\\
\\
Bicchieri's is not trying to show how this can be used to figure out alternative strategies, but rather to show that despite the Backward Induction, players might rationally play these alternative strategies.


























\subsection{Aumann}
Aumanns paper is the latest of the three in chronological order. He begins by mentioning the idea of common knowledge of rationality, and cites both Bicchieri and Pettit as examples of how this idea is difficult to formalise.

\section{Compare and contrast}

\section{My own views}
I find myself sympathetic towards the

\end{document}